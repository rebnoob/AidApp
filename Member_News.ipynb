{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rebnoob/AidApp/blob/main/Member_News.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgmM_wQzOMXA"
      },
      "source": [
        "#Install Prerequisite\n",
        "Just run it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "BjRTmwFC8gmK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cbd883d-c238-4d6e-b24f-1f90000005bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gnews in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: feedparser~=6.0.2 in /usr/local/lib/python3.10/dist-packages (from gnews) (6.0.10)\n",
            "Requirement already satisfied: bs4~=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gnews) (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4~=4.9.3 in /usr/local/lib/python3.10/dist-packages (from gnews) (4.9.3)\n",
            "Requirement already satisfied: pymongo~=3.12.0 in /usr/local/lib/python3.10/dist-packages (from gnews) (3.12.3)\n",
            "Requirement already satisfied: dnspython~=1.16.0 in /usr/local/lib/python3.10/dist-packages (from gnews) (1.16.0)\n",
            "Requirement already satisfied: python-dotenv~=0.19.0 in /usr/local/lib/python3.10/dist-packages (from gnews) (0.19.2)\n",
            "Requirement already satisfied: requests==2.26.0 in /usr/local/lib/python3.10/dist-packages (from gnews) (2.26.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.26.0->gnews) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.26.0->gnews) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests==2.26.0->gnews) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.26.0->gnews) (3.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4~=4.9.3->gnews) (2.4.1)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser~=6.0.2->gnews) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gnews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y8DSSIh9C1q"
      },
      "source": [
        "#Get News from Google"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_33eYnvJ2O3"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBO1q_M9OhS0"
      },
      "source": [
        "This code for importing the excel sheet. Make sure the excel sheet follows the format of the sample. Drag it to the file folder and change the name below to the name of the excel sheet. File name example \"region1\" or \"region2\". No CAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "JciXh6AJOetP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "93efaff4-8608-46e8-9572-f2fcf21a9319"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            last_name first_name middle_name suffix nickname  \\\n",
              "0               Casar   Gregorio     Eduardo    NaN      NaN   \n",
              "1               Babin      Brian         NaN    NaN      NaN   \n",
              "2             Doggett      Lloyd          A.    NaN      NaN   \n",
              "3                Hunt     Wesley      Parish    NaN      NaN   \n",
              "4               Moore      Blake       David    NaN      NaN   \n",
              "5             Stewart      Chris         NaN    NaN      NaN   \n",
              "6              Curtis       John          R.    NaN      NaN   \n",
              "7               Owens   Clarence         NaN    NaN  Burgess   \n",
              "8             Wittman     Robert          J.    NaN      NaN   \n",
              "9             Kiggans   Jennifer         Ann    NaN      NaN   \n",
              "10              Scott     Robert          C.    NaN    Bobby   \n",
              "11          McClellan   Jennifer         NaN    NaN      NaN   \n",
              "12               Good     Robert          G.    NaN      Bob   \n",
              "13              Cline        Ben         NaN    NaN      NaN   \n",
              "14         Spanberger    Abigail       Davis    NaN      NaN   \n",
              "15              Beyer     Donald          S.    Jr.      NaN   \n",
              "16           Griffith         H.      Morgan    NaN      NaN   \n",
              "17             Wexton   Jennifer         NaN    NaN      NaN   \n",
              "18           Connolly     Gerald          E.    NaN      NaN   \n",
              "19           Plaskett     Stacey          E.    NaN      NaN   \n",
              "20             Balint      Becca          A.    NaN      NaN   \n",
              "21            DelBene      Suzan          K.    NaN      NaN   \n",
              "22             Larsen       Rick         NaN    NaN      NaN   \n",
              "23  Gluesenkamp Perez      Marie         NaN    NaN      NaN   \n",
              "24           Newhouse        Dan         NaN    NaN      NaN   \n",
              "25   McMorris Rodgers      Cathy        Anne    NaN      NaN   \n",
              "26             Kilmer      Derek         NaN    NaN      NaN   \n",
              "27            Jayapal    Pramila         NaN    NaN      NaN   \n",
              "28            Schrier        Kim         NaN    NaN      NaN   \n",
              "29              Smith       Adam         NaN    NaN      NaN   \n",
              "30         Strickland    Marilyn         NaN    NaN      NaN   \n",
              "31              Steil      Bryan         NaN    NaN      NaN   \n",
              "32              Pocan       Mark         NaN    NaN      NaN   \n",
              "33          Van Orden    Derrick     Francis    NaN      NaN   \n",
              "34              Moore       Gwen         NaN    NaN      NaN   \n",
              "35         Fitzgerald      Scott          L.    NaN      NaN   \n",
              "36           Grothman      Glenn         NaN    NaN      NaN   \n",
              "37            Tiffany     Thomas          P.    NaN      NaN   \n",
              "38          Gallagher       Mike         NaN    NaN      NaN   \n",
              "39             Miller      Carol          D.    NaN      NaN   \n",
              "40             Mooney  Alexander          X.    NaN      NaN   \n",
              "41            Hageman    Harriet      Maxine    NaN      NaN   \n",
              "\n",
              "                   full_name   birthday gender type state  ...  \\\n",
              "0                 Greg Casar 1989-05-04      M  rep    TX  ...   \n",
              "1                Brian Babin 1948-03-23      M  rep    TX  ...   \n",
              "2              Lloyd Doggett 1946-10-06      M  rep    TX  ...   \n",
              "3                Wesley Hunt 1981-11-13      M  rep    TX  ...   \n",
              "4             Blake D. Moore 1980-06-22      M  rep    UT  ...   \n",
              "5              Chris Stewart 1960-07-15      M  rep    UT  ...   \n",
              "6             John R. Curtis 1960-05-10      M  rep    UT  ...   \n",
              "7              Burgess Owens 1951-08-02      M  rep    UT  ...   \n",
              "8          Robert J. Wittman 1959-02-03      M  rep    VA  ...   \n",
              "9           Jennifer Kiggans 1971-06-18      F  rep    VA  ...   \n",
              "10   Robert C. \"Bobby\" Scott 1947-04-30      M  rep    VA  ...   \n",
              "11     Jennifer L. McClellan 1972-12-28      F  rep    VA  ...   \n",
              "12                  Bob Good 1965-09-11      M  rep    VA  ...   \n",
              "13                 Ben Cline 1972-02-29      M  rep    VA  ...   \n",
              "14  Abigail Davis Spanberger 1979-08-07      F  rep    VA  ...   \n",
              "15      Donald S. Beyer, Jr. 1950-06-20      M  rep    VA  ...   \n",
              "16        H. Morgan Griffith 1958-03-15      M  rep    VA  ...   \n",
              "17           Jennifer Wexton 1968-05-27      F  rep    VA  ...   \n",
              "18        Gerald E. Connolly 1950-03-30      M  rep    VA  ...   \n",
              "19        Stacey E. Plaskett 1966-05-13      F  rep    VI  ...   \n",
              "20              Becca Balint 1968-05-04      F  rep    VT  ...   \n",
              "21          Suzan K. DelBene 1962-02-17      F  rep    WA  ...   \n",
              "22               Rick Larsen 1965-06-15      M  rep    WA  ...   \n",
              "23   Marie Gluesenkamp Perez 1988-06-06      F  rep    WA  ...   \n",
              "24              Dan Newhouse 1955-07-10      M  rep    WA  ...   \n",
              "25    Cathy McMorris Rodgers 1969-05-22      F  rep    WA  ...   \n",
              "26              Derek Kilmer 1974-01-01      M  rep    WA  ...   \n",
              "27           Pramila Jayapal 1965-09-21      F  rep    WA  ...   \n",
              "28               Kim Schrier 1968-08-23      F  rep    WA  ...   \n",
              "29                Adam Smith 1965-06-15      M  rep    WA  ...   \n",
              "30        Marilyn Strickland 1962-09-25      F  rep    WA  ...   \n",
              "31               Bryan Steil 1981-03-30      M  rep    WI  ...   \n",
              "32                Mark Pocan 1964-08-14      M  rep    WI  ...   \n",
              "33         Derrick Van Orden 1969-09-15      M  rep    WI  ...   \n",
              "34                Gwen Moore 1951-04-18      F  rep    WI  ...   \n",
              "35          Scott Fitzgerald 1963-11-16      M  rep    WI  ...   \n",
              "36            Glenn Grothman 1955-07-03      M  rep    WI  ...   \n",
              "37         Thomas P. Tiffany 1957-12-30      M  rep    WI  ...   \n",
              "38            Mike Gallagher 1984-03-03      M  rep    WI  ...   \n",
              "39           Carol D. Miller 1950-11-04      F  rep    WV  ...   \n",
              "40       Alexander X. Mooney 1971-06-05      M  rep    WV  ...   \n",
              "41        Harriet M. Hageman 1962-10-18      F  rep    WY  ...   \n",
              "\n",
              "    opensecrets_id  lis_id    fec_ids   cspan_id govtrack_id votesmart_id  \\\n",
              "0              NaN     NaN  H2TX35144        NaN      456945     161953.0   \n",
              "1        N00005736     NaN  H6TX02079    44883.0      412655        360.0   \n",
              "2        N00006023     NaN  H4TX10028    36810.0      400111      21689.0   \n",
              "3              NaN     NaN  H0TX07170        NaN      456946     188147.0   \n",
              "4        N00046598     NaN  H0UT01205        NaN      456851          NaN   \n",
              "5        N00033932     NaN  H2UT02324    68466.0      412581     135930.0   \n",
              "6        N00041221     NaN  H8UT03238        NaN      412740     123390.0   \n",
              "7        N00045812     NaN  H0UT04076        NaN      456852          NaN   \n",
              "8        N00029459     NaN  H8VA01147  1028089.0      412255      58133.0   \n",
              "9              NaN     NaN  H2VA02064        NaN      456947     186387.0   \n",
              "10       N00002147     NaN  H6VA01117    25888.0      400364      27117.0   \n",
              "11             NaN     NaN  H4VA04066        NaN      456953      58655.0   \n",
              "12       N00045557     NaN  H0VA05160        NaN      456853          NaN   \n",
              "13       N00042296     NaN  H8VA06104        NaN      412832      50959.0   \n",
              "14       N00041418     NaN  H8VA07094        NaN      412833     179682.0   \n",
              "15       N00036018     NaN  H4VA08224    21141.0      412657       1707.0   \n",
              "16       N00032029     NaN  H0VA09055    62766.0      412485       5148.0   \n",
              "17       N00041002     NaN  H8VA10106        NaN      412834     147013.0   \n",
              "18       N00029891     NaN  H8VA11062  1015936.0      412272      95078.0   \n",
              "19       N00035000     NaN  H2VI00082    79090.0      412659     155929.0   \n",
              "20             NaN     NaN  H2VT01076        NaN      456948     154056.0   \n",
              "21       N00030693     NaN  H0WA08046  1033929.0      412505     126272.0   \n",
              "22       N00009759     NaN  H0WA02080    86610.0      400232      56231.0   \n",
              "23             NaN     NaN  H2WA03217        NaN      456949     207307.0   \n",
              "24       N00036403     NaN  H4WA04104    78315.0      412660      51522.0   \n",
              "25       N00026314     NaN  H4WA05077  1013063.0      400659       3217.0   \n",
              "26       N00034453     NaN  H2WA06129    68310.0      412583      51516.0   \n",
              "27       N00038858     NaN  H6WA07458  9267128.0      412730     153141.0   \n",
              "28       N00041606     NaN  H8WA08189        NaN      412835     181124.0   \n",
              "29       N00007833     NaN  H6WA09025    44329.0      400379        845.0   \n",
              "30       N00046320     NaN  H0WA10034        NaN      456854          NaN   \n",
              "31       N00043379     NaN  H8WI01156        NaN      412836     181289.0   \n",
              "32       N00033549     NaN  H2WI02124    79688.0      412585      26238.0   \n",
              "33             NaN     NaN  H0WI03175        NaN      456950     192343.0   \n",
              "34       N00026914     NaN  H4WI04183    42548.0      400661       3457.0   \n",
              "35       N00045434     NaN  H0WI05113        NaN      456855       3446.0   \n",
              "36       N00036409     NaN  H4WI06048    77282.0      412661       3493.0   \n",
              "37       N00045307     NaN  H0WI07101        NaN      456791          NaN   \n",
              "38       N00039330     NaN  H6WI08155   104067.0      412731     171843.0   \n",
              "39       N00041542     NaN  H8WV03097        NaN      412837      52123.0   \n",
              "40       N00033814     NaN  H4WV02080    76588.0      412662     145943.0   \n",
              "41             NaN     NaN  H2WY00166        NaN      456951     182961.0   \n",
              "\n",
              "                   ballotpedia_id washington_post_id icpsr_id  \\\n",
              "0                             NaN                NaN      NaN   \n",
              "1                     Brian Babin                NaN  21551.0   \n",
              "2                   Lloyd Doggett                NaN  29571.0   \n",
              "3    Wesley Hunt (Texas Congress)                NaN      NaN   \n",
              "4                             NaN                NaN      NaN   \n",
              "5                   Chris Stewart                NaN  21367.0   \n",
              "6              John Curtis (Utah)                NaN  21755.0   \n",
              "7                   Burgess Owens                NaN      NaN   \n",
              "8               Robert J. Wittman                NaN  20756.0   \n",
              "9                             NaN                NaN      NaN   \n",
              "10                Robert C. Scott                NaN  39307.0   \n",
              "11             Jennifer McClellan                NaN      NaN   \n",
              "12                            NaN                NaN      NaN   \n",
              "13                      Ben Cline                NaN  21908.0   \n",
              "14             Abigail Spanberger                NaN  21966.0   \n",
              "15                      Don Beyer                NaN  21554.0   \n",
              "16                Morgan Griffith                NaN  21191.0   \n",
              "17                Jennifer Wexton                NaN  21983.0   \n",
              "18                Gerald Connolly                NaN  20952.0   \n",
              "19                            NaN                NaN      NaN   \n",
              "20                            NaN                NaN      NaN   \n",
              "21                  Suzan DelBene                NaN  31101.0   \n",
              "22                    Rick Larsen                NaN  20145.0   \n",
              "23        Marie Gluesenkamp Perez                NaN      NaN   \n",
              "24                   Dan Newhouse                NaN  21556.0   \n",
              "25         Cathy McMorris Rodgers                NaN  20535.0   \n",
              "26                   Derek Kilmer                NaN  21368.0   \n",
              "27                Pramila Jayapal                NaN  21726.0   \n",
              "28                    Kim Schrier                NaN  21962.0   \n",
              "29                     Adam Smith                NaN  29768.0   \n",
              "30                            NaN                NaN      NaN   \n",
              "31                    Bryan Steil                NaN  21970.0   \n",
              "32                     Mark Pocan                NaN  21370.0   \n",
              "33              Derrick Van Orden                NaN      NaN   \n",
              "34                     Gwen Moore                NaN  20537.0   \n",
              "35                            NaN                NaN      NaN   \n",
              "36                 Glenn Grothman                NaN  21559.0   \n",
              "37                    Tom Tiffany                NaN      NaN   \n",
              "38  Michael Gallagher (Wisconsin)                NaN  21720.0   \n",
              "39   Carol Miller (West Virginia)                NaN  21946.0   \n",
              "40               Alexander Mooney                NaN  21557.0   \n",
              "41                Harriet Hageman                NaN      NaN   \n",
              "\n",
              "                            wikipedia_id  \n",
              "0                             Greg Casar  \n",
              "1                            Brian Babin  \n",
              "2                          Lloyd Doggett  \n",
              "3                            Wesley Hunt  \n",
              "4                            Blake Moore  \n",
              "5             Chris Stewart (politician)  \n",
              "6          John Curtis (Utah politician)  \n",
              "7                          Burgess Owens  \n",
              "8                            Rob Wittman  \n",
              "9                            Jen Kiggans  \n",
              "10              Bobby Scott (politician)  \n",
              "11                    Jennifer McClellan  \n",
              "12                              Bob Good  \n",
              "13                             Ben Cline  \n",
              "14                    Abigail Spanberger  \n",
              "15                             Don Beyer  \n",
              "16                       Morgan Griffith  \n",
              "17                       Jennifer Wexton  \n",
              "18                        Gerry Connolly  \n",
              "19                       Stacey Plaskett  \n",
              "20                          Becca Balint  \n",
              "21                         Suzan DelBene  \n",
              "22                           Rick Larsen  \n",
              "23               Marie Gluesenkamp Perez  \n",
              "24                          Dan Newhouse  \n",
              "25                Cathy McMorris Rodgers  \n",
              "26                          Derek Kilmer  \n",
              "27                       Pramila Jayapal  \n",
              "28                           Kim Schrier  \n",
              "29    Adam Smith (Washington politician)  \n",
              "30                    Marilyn Strickland  \n",
              "31                           Bryan Steil  \n",
              "32                            Mark Pocan  \n",
              "33                     Derrick Van Orden  \n",
              "34                            Gwen Moore  \n",
              "35         Scott Fitzgerald (politician)  \n",
              "36                        Glenn Grothman  \n",
              "37                           Tom Tiffany  \n",
              "38  Mike Gallagher (American politician)  \n",
              "39             Carol Miller (politician)  \n",
              "40                           Alex Mooney  \n",
              "41                       Harriet Hageman  \n",
              "\n",
              "[42 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b72fdc5-fd85-424f-b401-77c2484c0053\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>last_name</th>\n",
              "      <th>first_name</th>\n",
              "      <th>middle_name</th>\n",
              "      <th>suffix</th>\n",
              "      <th>nickname</th>\n",
              "      <th>full_name</th>\n",
              "      <th>birthday</th>\n",
              "      <th>gender</th>\n",
              "      <th>type</th>\n",
              "      <th>state</th>\n",
              "      <th>...</th>\n",
              "      <th>opensecrets_id</th>\n",
              "      <th>lis_id</th>\n",
              "      <th>fec_ids</th>\n",
              "      <th>cspan_id</th>\n",
              "      <th>govtrack_id</th>\n",
              "      <th>votesmart_id</th>\n",
              "      <th>ballotpedia_id</th>\n",
              "      <th>washington_post_id</th>\n",
              "      <th>icpsr_id</th>\n",
              "      <th>wikipedia_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Casar</td>\n",
              "      <td>Gregorio</td>\n",
              "      <td>Eduardo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Greg Casar</td>\n",
              "      <td>1989-05-04</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>TX</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H2TX35144</td>\n",
              "      <td>NaN</td>\n",
              "      <td>456945</td>\n",
              "      <td>161953.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Greg Casar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Babin</td>\n",
              "      <td>Brian</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Brian Babin</td>\n",
              "      <td>1948-03-23</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>TX</td>\n",
              "      <td>...</td>\n",
              "      <td>N00005736</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H6TX02079</td>\n",
              "      <td>44883.0</td>\n",
              "      <td>412655</td>\n",
              "      <td>360.0</td>\n",
              "      <td>Brian Babin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21551.0</td>\n",
              "      <td>Brian Babin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Doggett</td>\n",
              "      <td>Lloyd</td>\n",
              "      <td>A.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Lloyd Doggett</td>\n",
              "      <td>1946-10-06</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>TX</td>\n",
              "      <td>...</td>\n",
              "      <td>N00006023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H4TX10028</td>\n",
              "      <td>36810.0</td>\n",
              "      <td>400111</td>\n",
              "      <td>21689.0</td>\n",
              "      <td>Lloyd Doggett</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29571.0</td>\n",
              "      <td>Lloyd Doggett</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hunt</td>\n",
              "      <td>Wesley</td>\n",
              "      <td>Parish</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wesley Hunt</td>\n",
              "      <td>1981-11-13</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>TX</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H0TX07170</td>\n",
              "      <td>NaN</td>\n",
              "      <td>456946</td>\n",
              "      <td>188147.0</td>\n",
              "      <td>Wesley Hunt (Texas Congress)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wesley Hunt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Moore</td>\n",
              "      <td>Blake</td>\n",
              "      <td>David</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Blake D. Moore</td>\n",
              "      <td>1980-06-22</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>UT</td>\n",
              "      <td>...</td>\n",
              "      <td>N00046598</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H0UT01205</td>\n",
              "      <td>NaN</td>\n",
              "      <td>456851</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Blake Moore</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Stewart</td>\n",
              "      <td>Chris</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Chris Stewart</td>\n",
              "      <td>1960-07-15</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>UT</td>\n",
              "      <td>...</td>\n",
              "      <td>N00033932</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H2UT02324</td>\n",
              "      <td>68466.0</td>\n",
              "      <td>412581</td>\n",
              "      <td>135930.0</td>\n",
              "      <td>Chris Stewart</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21367.0</td>\n",
              "      <td>Chris Stewart (politician)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Curtis</td>\n",
              "      <td>John</td>\n",
              "      <td>R.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>John R. Curtis</td>\n",
              "      <td>1960-05-10</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>UT</td>\n",
              "      <td>...</td>\n",
              "      <td>N00041221</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H8UT03238</td>\n",
              "      <td>NaN</td>\n",
              "      <td>412740</td>\n",
              "      <td>123390.0</td>\n",
              "      <td>John Curtis (Utah)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21755.0</td>\n",
              "      <td>John Curtis (Utah politician)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Owens</td>\n",
              "      <td>Clarence</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Burgess</td>\n",
              "      <td>Burgess Owens</td>\n",
              "      <td>1951-08-02</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>UT</td>\n",
              "      <td>...</td>\n",
              "      <td>N00045812</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H0UT04076</td>\n",
              "      <td>NaN</td>\n",
              "      <td>456852</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Burgess Owens</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Burgess Owens</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Wittman</td>\n",
              "      <td>Robert</td>\n",
              "      <td>J.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Robert J. Wittman</td>\n",
              "      <td>1959-02-03</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>VA</td>\n",
              "      <td>...</td>\n",
              "      <td>N00029459</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H8VA01147</td>\n",
              "      <td>1028089.0</td>\n",
              "      <td>412255</td>\n",
              "      <td>58133.0</td>\n",
              "      <td>Robert J. Wittman</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20756.0</td>\n",
              "      <td>Rob Wittman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Kiggans</td>\n",
              "      <td>Jennifer</td>\n",
              "      <td>Ann</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Jennifer Kiggans</td>\n",
              "      <td>1971-06-18</td>\n",
              "      <td>F</td>\n",
              "      <td>rep</td>\n",
              "      <td>VA</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H2VA02064</td>\n",
              "      <td>NaN</td>\n",
              "      <td>456947</td>\n",
              "      <td>186387.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Jen Kiggans</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Scott</td>\n",
              "      <td>Robert</td>\n",
              "      <td>C.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bobby</td>\n",
              "      <td>Robert C. \"Bobby\" Scott</td>\n",
              "      <td>1947-04-30</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>VA</td>\n",
              "      <td>...</td>\n",
              "      <td>N00002147</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H6VA01117</td>\n",
              "      <td>25888.0</td>\n",
              "      <td>400364</td>\n",
              "      <td>27117.0</td>\n",
              "      <td>Robert C. Scott</td>\n",
              "      <td>NaN</td>\n",
              "      <td>39307.0</td>\n",
              "      <td>Bobby Scott (politician)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>McClellan</td>\n",
              "      <td>Jennifer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Jennifer L. McClellan</td>\n",
              "      <td>1972-12-28</td>\n",
              "      <td>F</td>\n",
              "      <td>rep</td>\n",
              "      <td>VA</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H4VA04066</td>\n",
              "      <td>NaN</td>\n",
              "      <td>456953</td>\n",
              "      <td>58655.0</td>\n",
              "      <td>Jennifer McClellan</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Jennifer McClellan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Good</td>\n",
              "      <td>Robert</td>\n",
              "      <td>G.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bob</td>\n",
              "      <td>Bob Good</td>\n",
              "      <td>1965-09-11</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>VA</td>\n",
              "      <td>...</td>\n",
              "      <td>N00045557</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H0VA05160</td>\n",
              "      <td>NaN</td>\n",
              "      <td>456853</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bob Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Cline</td>\n",
              "      <td>Ben</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ben Cline</td>\n",
              "      <td>1972-02-29</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>VA</td>\n",
              "      <td>...</td>\n",
              "      <td>N00042296</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H8VA06104</td>\n",
              "      <td>NaN</td>\n",
              "      <td>412832</td>\n",
              "      <td>50959.0</td>\n",
              "      <td>Ben Cline</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21908.0</td>\n",
              "      <td>Ben Cline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Spanberger</td>\n",
              "      <td>Abigail</td>\n",
              "      <td>Davis</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Abigail Davis Spanberger</td>\n",
              "      <td>1979-08-07</td>\n",
              "      <td>F</td>\n",
              "      <td>rep</td>\n",
              "      <td>VA</td>\n",
              "      <td>...</td>\n",
              "      <td>N00041418</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H8VA07094</td>\n",
              "      <td>NaN</td>\n",
              "      <td>412833</td>\n",
              "      <td>179682.0</td>\n",
              "      <td>Abigail Spanberger</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21966.0</td>\n",
              "      <td>Abigail Spanberger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Beyer</td>\n",
              "      <td>Donald</td>\n",
              "      <td>S.</td>\n",
              "      <td>Jr.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Donald S. Beyer, Jr.</td>\n",
              "      <td>1950-06-20</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>VA</td>\n",
              "      <td>...</td>\n",
              "      <td>N00036018</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H4VA08224</td>\n",
              "      <td>21141.0</td>\n",
              "      <td>412657</td>\n",
              "      <td>1707.0</td>\n",
              "      <td>Don Beyer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21554.0</td>\n",
              "      <td>Don Beyer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Griffith</td>\n",
              "      <td>H.</td>\n",
              "      <td>Morgan</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H. Morgan Griffith</td>\n",
              "      <td>1958-03-15</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>VA</td>\n",
              "      <td>...</td>\n",
              "      <td>N00032029</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H0VA09055</td>\n",
              "      <td>62766.0</td>\n",
              "      <td>412485</td>\n",
              "      <td>5148.0</td>\n",
              "      <td>Morgan Griffith</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21191.0</td>\n",
              "      <td>Morgan Griffith</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Wexton</td>\n",
              "      <td>Jennifer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Jennifer Wexton</td>\n",
              "      <td>1968-05-27</td>\n",
              "      <td>F</td>\n",
              "      <td>rep</td>\n",
              "      <td>VA</td>\n",
              "      <td>...</td>\n",
              "      <td>N00041002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H8VA10106</td>\n",
              "      <td>NaN</td>\n",
              "      <td>412834</td>\n",
              "      <td>147013.0</td>\n",
              "      <td>Jennifer Wexton</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21983.0</td>\n",
              "      <td>Jennifer Wexton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Connolly</td>\n",
              "      <td>Gerald</td>\n",
              "      <td>E.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Gerald E. Connolly</td>\n",
              "      <td>1950-03-30</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>VA</td>\n",
              "      <td>...</td>\n",
              "      <td>N00029891</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H8VA11062</td>\n",
              "      <td>1015936.0</td>\n",
              "      <td>412272</td>\n",
              "      <td>95078.0</td>\n",
              "      <td>Gerald Connolly</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20952.0</td>\n",
              "      <td>Gerry Connolly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Plaskett</td>\n",
              "      <td>Stacey</td>\n",
              "      <td>E.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Stacey E. Plaskett</td>\n",
              "      <td>1966-05-13</td>\n",
              "      <td>F</td>\n",
              "      <td>rep</td>\n",
              "      <td>VI</td>\n",
              "      <td>...</td>\n",
              "      <td>N00035000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H2VI00082</td>\n",
              "      <td>79090.0</td>\n",
              "      <td>412659</td>\n",
              "      <td>155929.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Stacey Plaskett</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Balint</td>\n",
              "      <td>Becca</td>\n",
              "      <td>A.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Becca Balint</td>\n",
              "      <td>1968-05-04</td>\n",
              "      <td>F</td>\n",
              "      <td>rep</td>\n",
              "      <td>VT</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H2VT01076</td>\n",
              "      <td>NaN</td>\n",
              "      <td>456948</td>\n",
              "      <td>154056.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Becca Balint</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>DelBene</td>\n",
              "      <td>Suzan</td>\n",
              "      <td>K.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Suzan K. DelBene</td>\n",
              "      <td>1962-02-17</td>\n",
              "      <td>F</td>\n",
              "      <td>rep</td>\n",
              "      <td>WA</td>\n",
              "      <td>...</td>\n",
              "      <td>N00030693</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H0WA08046</td>\n",
              "      <td>1033929.0</td>\n",
              "      <td>412505</td>\n",
              "      <td>126272.0</td>\n",
              "      <td>Suzan DelBene</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31101.0</td>\n",
              "      <td>Suzan DelBene</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Larsen</td>\n",
              "      <td>Rick</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Rick Larsen</td>\n",
              "      <td>1965-06-15</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>WA</td>\n",
              "      <td>...</td>\n",
              "      <td>N00009759</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H0WA02080</td>\n",
              "      <td>86610.0</td>\n",
              "      <td>400232</td>\n",
              "      <td>56231.0</td>\n",
              "      <td>Rick Larsen</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20145.0</td>\n",
              "      <td>Rick Larsen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Gluesenkamp Perez</td>\n",
              "      <td>Marie</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Marie Gluesenkamp Perez</td>\n",
              "      <td>1988-06-06</td>\n",
              "      <td>F</td>\n",
              "      <td>rep</td>\n",
              "      <td>WA</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H2WA03217</td>\n",
              "      <td>NaN</td>\n",
              "      <td>456949</td>\n",
              "      <td>207307.0</td>\n",
              "      <td>Marie Gluesenkamp Perez</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Marie Gluesenkamp Perez</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Newhouse</td>\n",
              "      <td>Dan</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dan Newhouse</td>\n",
              "      <td>1955-07-10</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>WA</td>\n",
              "      <td>...</td>\n",
              "      <td>N00036403</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H4WA04104</td>\n",
              "      <td>78315.0</td>\n",
              "      <td>412660</td>\n",
              "      <td>51522.0</td>\n",
              "      <td>Dan Newhouse</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21556.0</td>\n",
              "      <td>Dan Newhouse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>McMorris Rodgers</td>\n",
              "      <td>Cathy</td>\n",
              "      <td>Anne</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Cathy McMorris Rodgers</td>\n",
              "      <td>1969-05-22</td>\n",
              "      <td>F</td>\n",
              "      <td>rep</td>\n",
              "      <td>WA</td>\n",
              "      <td>...</td>\n",
              "      <td>N00026314</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H4WA05077</td>\n",
              "      <td>1013063.0</td>\n",
              "      <td>400659</td>\n",
              "      <td>3217.0</td>\n",
              "      <td>Cathy McMorris Rodgers</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20535.0</td>\n",
              "      <td>Cathy McMorris Rodgers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Kilmer</td>\n",
              "      <td>Derek</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Derek Kilmer</td>\n",
              "      <td>1974-01-01</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>WA</td>\n",
              "      <td>...</td>\n",
              "      <td>N00034453</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H2WA06129</td>\n",
              "      <td>68310.0</td>\n",
              "      <td>412583</td>\n",
              "      <td>51516.0</td>\n",
              "      <td>Derek Kilmer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21368.0</td>\n",
              "      <td>Derek Kilmer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Jayapal</td>\n",
              "      <td>Pramila</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pramila Jayapal</td>\n",
              "      <td>1965-09-21</td>\n",
              "      <td>F</td>\n",
              "      <td>rep</td>\n",
              "      <td>WA</td>\n",
              "      <td>...</td>\n",
              "      <td>N00038858</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H6WA07458</td>\n",
              "      <td>9267128.0</td>\n",
              "      <td>412730</td>\n",
              "      <td>153141.0</td>\n",
              "      <td>Pramila Jayapal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21726.0</td>\n",
              "      <td>Pramila Jayapal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Schrier</td>\n",
              "      <td>Kim</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Kim Schrier</td>\n",
              "      <td>1968-08-23</td>\n",
              "      <td>F</td>\n",
              "      <td>rep</td>\n",
              "      <td>WA</td>\n",
              "      <td>...</td>\n",
              "      <td>N00041606</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H8WA08189</td>\n",
              "      <td>NaN</td>\n",
              "      <td>412835</td>\n",
              "      <td>181124.0</td>\n",
              "      <td>Kim Schrier</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21962.0</td>\n",
              "      <td>Kim Schrier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Smith</td>\n",
              "      <td>Adam</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Adam Smith</td>\n",
              "      <td>1965-06-15</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>WA</td>\n",
              "      <td>...</td>\n",
              "      <td>N00007833</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H6WA09025</td>\n",
              "      <td>44329.0</td>\n",
              "      <td>400379</td>\n",
              "      <td>845.0</td>\n",
              "      <td>Adam Smith</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29768.0</td>\n",
              "      <td>Adam Smith (Washington politician)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Strickland</td>\n",
              "      <td>Marilyn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Marilyn Strickland</td>\n",
              "      <td>1962-09-25</td>\n",
              "      <td>F</td>\n",
              "      <td>rep</td>\n",
              "      <td>WA</td>\n",
              "      <td>...</td>\n",
              "      <td>N00046320</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H0WA10034</td>\n",
              "      <td>NaN</td>\n",
              "      <td>456854</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Marilyn Strickland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Steil</td>\n",
              "      <td>Bryan</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bryan Steil</td>\n",
              "      <td>1981-03-30</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>WI</td>\n",
              "      <td>...</td>\n",
              "      <td>N00043379</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H8WI01156</td>\n",
              "      <td>NaN</td>\n",
              "      <td>412836</td>\n",
              "      <td>181289.0</td>\n",
              "      <td>Bryan Steil</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21970.0</td>\n",
              "      <td>Bryan Steil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Pocan</td>\n",
              "      <td>Mark</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mark Pocan</td>\n",
              "      <td>1964-08-14</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>WI</td>\n",
              "      <td>...</td>\n",
              "      <td>N00033549</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H2WI02124</td>\n",
              "      <td>79688.0</td>\n",
              "      <td>412585</td>\n",
              "      <td>26238.0</td>\n",
              "      <td>Mark Pocan</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21370.0</td>\n",
              "      <td>Mark Pocan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Van Orden</td>\n",
              "      <td>Derrick</td>\n",
              "      <td>Francis</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Derrick Van Orden</td>\n",
              "      <td>1969-09-15</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>WI</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H0WI03175</td>\n",
              "      <td>NaN</td>\n",
              "      <td>456950</td>\n",
              "      <td>192343.0</td>\n",
              "      <td>Derrick Van Orden</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Derrick Van Orden</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Moore</td>\n",
              "      <td>Gwen</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Gwen Moore</td>\n",
              "      <td>1951-04-18</td>\n",
              "      <td>F</td>\n",
              "      <td>rep</td>\n",
              "      <td>WI</td>\n",
              "      <td>...</td>\n",
              "      <td>N00026914</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H4WI04183</td>\n",
              "      <td>42548.0</td>\n",
              "      <td>400661</td>\n",
              "      <td>3457.0</td>\n",
              "      <td>Gwen Moore</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20537.0</td>\n",
              "      <td>Gwen Moore</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Fitzgerald</td>\n",
              "      <td>Scott</td>\n",
              "      <td>L.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scott Fitzgerald</td>\n",
              "      <td>1963-11-16</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>WI</td>\n",
              "      <td>...</td>\n",
              "      <td>N00045434</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H0WI05113</td>\n",
              "      <td>NaN</td>\n",
              "      <td>456855</td>\n",
              "      <td>3446.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scott Fitzgerald (politician)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Grothman</td>\n",
              "      <td>Glenn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Glenn Grothman</td>\n",
              "      <td>1955-07-03</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>WI</td>\n",
              "      <td>...</td>\n",
              "      <td>N00036409</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H4WI06048</td>\n",
              "      <td>77282.0</td>\n",
              "      <td>412661</td>\n",
              "      <td>3493.0</td>\n",
              "      <td>Glenn Grothman</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21559.0</td>\n",
              "      <td>Glenn Grothman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Tiffany</td>\n",
              "      <td>Thomas</td>\n",
              "      <td>P.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Thomas P. Tiffany</td>\n",
              "      <td>1957-12-30</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>WI</td>\n",
              "      <td>...</td>\n",
              "      <td>N00045307</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H0WI07101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>456791</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tom Tiffany</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tom Tiffany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Gallagher</td>\n",
              "      <td>Mike</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mike Gallagher</td>\n",
              "      <td>1984-03-03</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>WI</td>\n",
              "      <td>...</td>\n",
              "      <td>N00039330</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H6WI08155</td>\n",
              "      <td>104067.0</td>\n",
              "      <td>412731</td>\n",
              "      <td>171843.0</td>\n",
              "      <td>Michael Gallagher (Wisconsin)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21720.0</td>\n",
              "      <td>Mike Gallagher (American politician)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Miller</td>\n",
              "      <td>Carol</td>\n",
              "      <td>D.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Carol D. Miller</td>\n",
              "      <td>1950-11-04</td>\n",
              "      <td>F</td>\n",
              "      <td>rep</td>\n",
              "      <td>WV</td>\n",
              "      <td>...</td>\n",
              "      <td>N00041542</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H8WV03097</td>\n",
              "      <td>NaN</td>\n",
              "      <td>412837</td>\n",
              "      <td>52123.0</td>\n",
              "      <td>Carol Miller (West Virginia)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21946.0</td>\n",
              "      <td>Carol Miller (politician)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Mooney</td>\n",
              "      <td>Alexander</td>\n",
              "      <td>X.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alexander X. Mooney</td>\n",
              "      <td>1971-06-05</td>\n",
              "      <td>M</td>\n",
              "      <td>rep</td>\n",
              "      <td>WV</td>\n",
              "      <td>...</td>\n",
              "      <td>N00033814</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H4WV02080</td>\n",
              "      <td>76588.0</td>\n",
              "      <td>412662</td>\n",
              "      <td>145943.0</td>\n",
              "      <td>Alexander Mooney</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21557.0</td>\n",
              "      <td>Alex Mooney</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Hageman</td>\n",
              "      <td>Harriet</td>\n",
              "      <td>Maxine</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Harriet M. Hageman</td>\n",
              "      <td>1962-10-18</td>\n",
              "      <td>F</td>\n",
              "      <td>rep</td>\n",
              "      <td>WY</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>H2WY00166</td>\n",
              "      <td>NaN</td>\n",
              "      <td>456951</td>\n",
              "      <td>182961.0</td>\n",
              "      <td>Harriet Hageman</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Harriet Hageman</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>42 rows  36 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b72fdc5-fd85-424f-b401-77c2484c0053')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b72fdc5-fd85-424f-b401-77c2484c0053 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b72fdc5-fd85-424f-b401-77c2484c0053');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "filename = \"nameList.xlsx\" #@param {type:\"string\"}\n",
        "sheet_name = \"Region5\" #@param {type:\"string\"}\n",
        "\n",
        "df = pd.read_excel(filename, sheet_name=sheet_name)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5om1C1lPHbZ"
      },
      "source": [
        "The start date doesn't work, just ignore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW3qCETy8hpH"
      },
      "outputs": [],
      "source": [
        "google_news = GNews()\n",
        "google_news.max_results = 10  # number of responses across a keyword\n",
        "google_news.country = 'United States'  # News from a specific country\n",
        "google_news.language = 'english'  # News in a specific language\n",
        "google_news.exclude_websites = [\"congress.gov\",'house.gov',\"senate.gov\"]  # Exclude news from specific websites\n",
        "google_news.start_date = (2023, 7, 1) # Search from 1st Jan 2020"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wFNMA7fTX9S"
      },
      "outputs": [],
      "source": [
        "news_list = pd.DataFrame(columns=['Name','Title','Date','URL'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD0_4hbzNMVn"
      },
      "source": [
        "## Get Individual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "g62myRGpa8Lp"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from gnews import GNews\n",
        "\n",
        "async def fetch(session, url):\n",
        "    async with session.get(url) as response:\n",
        "        return await response.text()\n",
        "\n",
        "async def process_news(info, seven_days_ago, rep):\n",
        "    date_format = '%a, %d %b %Y %H:%M:%S %Z'\n",
        "    news_row = None\n",
        "    try:\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            response = await fetch(session, info[\"url\"])\n",
        "            if datetime.strptime(info[\"published date\"], date_format) >= seven_days_ago:\n",
        "                if response and not response.startswith(\"https://consent.google.com/\"):\n",
        "                    #print(info[\"title\"] + info[\"published date\"])\n",
        "                    final_url = extract_final_url(response)\n",
        "                    if final_url:\n",
        "                        #print(final_url)\n",
        "                        news_row = {\n",
        "                            'Name': rep,\n",
        "                            'Title': info[\"title\"],\n",
        "                            'Date': info[\"published date\"],\n",
        "                            'URL': final_url\n",
        "                        }\n",
        "    except aiohttp.ClientError as e:\n",
        "        print(\"URL not working:\", e)\n",
        "\n",
        "    return pd.DataFrame(news_row, index=[0]) if news_row else None  # Return None if conditions are not met\n",
        "\n",
        "def extract_final_url(html_content):\n",
        "    match = re.search(r'<a\\s+href=[\\'\"]?([^\\'\" >]+)', html_content)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    return None\n",
        "\n",
        "\n",
        "async def main():\n",
        "    rep = \"Rep.Mike Levin\"\n",
        "    google_news = GNews()\n",
        "    google_news.max_results = 10\n",
        "    google_news.country = 'United States'\n",
        "    google_news.language = 'english'\n",
        "    google_news.exclude_websites = [\"congress.gov\", 'house.gov', \"senate.gov\"]\n",
        "    google_news.start_date = (2023, 7, 1)\n",
        "    news_list = pd.DataFrame(columns=['Name', 'Title', 'Date', 'URL'])\n",
        "    seven_days_ago = datetime.now() - timedelta(days=7)\n",
        "\n",
        "    news = google_news.get_news(rep)\n",
        "\n",
        "    tasks = []\n",
        "    for info in news:\n",
        "        task = asyncio.create_task(process_news(info, seven_days_ago, rep))\n",
        "        tasks.append(task)\n",
        "\n",
        "    result = await asyncio.gather(*tasks)\n",
        "    news_list = pd.concat([df for df in result if df is not None], ignore_index=True)  # Concatenate non-empty DataFrames\n",
        "\n",
        "    return news_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "3yVdGUWmgNSc",
        "outputId": "468060df-6e62-4c08-b364-3733baf4a647"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-73ccc6cb67eb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnews_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-103-58378e2f0f15>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mnews_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Concatenate non-empty DataFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnews_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;36m1\u001b[0m   \u001b[0;36m3\u001b[0m   \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \"\"\"\n\u001b[0;32m--> 368\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    news_list = await main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "iXWW2Utsj0TW",
        "outputId": "66a2ad1b-a066-4b1e-b9b7-46fa2fa1cb8c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8547582c-c7c6-4f9b-baa2-4a12072026b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Title</th>\n",
              "      <th>Date</th>\n",
              "      <th>URL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rep.Mike Levin</td>\n",
              "      <td>In Orange Countys open congressional race, do...</td>\n",
              "      <td>Mon, 03 Jul 2023 16:30:37 GMT</td>\n",
              "      <td>https://www.ocregister.com/2023/07/03/in-orang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rep.Mike Levin</td>\n",
              "      <td>Reps. Peters, Vargas, Jacobs, &amp; Levin Submit N...</td>\n",
              "      <td>Fri, 30 Jun 2023 22:53:38 GMT</td>\n",
              "      <td>https://scottpeters.house.gov/2023/6/reps-pete...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rep.Mike Levin</td>\n",
              "      <td>Huffman, Levin to introduce bills to protect P...</td>\n",
              "      <td>Wed, 28 Jun 2023 03:30:59 GMT</td>\n",
              "      <td>https://www.triplicate.com/news/huffman-levin-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rep.Mike Levin</td>\n",
              "      <td>Legislation Would Improve GI Bill, Other VA Se...</td>\n",
              "      <td>Tue, 27 Jun 2023 12:50:00 GMT</td>\n",
              "      <td>https://www.ngaus.org/newsroom/legislation-wou...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8547582c-c7c6-4f9b-baa2-4a12072026b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8547582c-c7c6-4f9b-baa2-4a12072026b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8547582c-c7c6-4f9b-baa2-4a12072026b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             Name                                              Title  \\\n",
              "0  Rep.Mike Levin  In Orange Countys open congressional race, do...   \n",
              "1  Rep.Mike Levin  Reps. Peters, Vargas, Jacobs, & Levin Submit N...   \n",
              "2  Rep.Mike Levin  Huffman, Levin to introduce bills to protect P...   \n",
              "3  Rep.Mike Levin  Legislation Would Improve GI Bill, Other VA Se...   \n",
              "\n",
              "                            Date  \\\n",
              "0  Mon, 03 Jul 2023 16:30:37 GMT   \n",
              "1  Fri, 30 Jun 2023 22:53:38 GMT   \n",
              "2  Wed, 28 Jun 2023 03:30:59 GMT   \n",
              "3  Tue, 27 Jun 2023 12:50:00 GMT   \n",
              "\n",
              "                                                 URL  \n",
              "0  https://www.ocregister.com/2023/07/03/in-orang...  \n",
              "1  https://scottpeters.house.gov/2023/6/reps-pete...  \n",
              "2  https://www.triplicate.com/news/huffman-levin-...  \n",
              "3  https://www.ngaus.org/newsroom/legislation-wou...  "
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "news_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2owA-f5qWTTE"
      },
      "source": [
        "## List + Get Article"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhsSCCgkPSVw"
      },
      "source": [
        "Once you load the documents, this should be fully automatic. It will find all the news about the rep for you. If this is taking too long to load, click on the loading button \"ONCE\" and only once, each time it gets stucked."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJkP-b7YHFPX"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from gnews import GNews\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "\n",
        "async def fetch(session, url):\n",
        "    async with session.get(url) as response:\n",
        "        return await response.text()\n",
        "\n",
        "async def process_news(info, seven_days_ago, rep):\n",
        "    date_format = '%a, %d %b %Y %H:%M:%S %Z'\n",
        "    news_row = None\n",
        "    try:\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            response = await fetch(session, info[\"url\"])\n",
        "            # Check if the published date is within the last seven days\n",
        "            if datetime.strptime(info[\"published date\"], date_format) >= seven_days_ago:\n",
        "                if response and not response.startswith(\"https://consent.google.com/\"):\n",
        "                    final_url = extract_final_url(response)\n",
        "                    if final_url:\n",
        "                        # Create a dictionary with the news information\n",
        "                        news_row = {\n",
        "                            'Name': rep,\n",
        "                            'Title': info[\"title\"],\n",
        "                            'Date': info[\"published date\"],\n",
        "                            'URL': final_url\n",
        "                        }\n",
        "    except aiohttp.ClientError as e:\n",
        "        print(\"URL not working:\", e)\n",
        "\n",
        "    # Return a DataFrame with the news information or None if no news row was created\n",
        "    return pd.DataFrame(news_row, index=[0]) if news_row else None\n",
        "\n",
        "def extract_final_url(html_content):\n",
        "    # Use regex to extract the final URL from the HTML content\n",
        "    match = re.search(r'<a\\s+href=[\\'\"]?([^\\'\" >]+)', html_content)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    return None\n",
        "\n",
        "async def fetch_result_text(index, url):\n",
        "    lexper_url = \"https://lexper.p.rapidapi.com/v1.1/extract\"\n",
        "    querystring = {\"url\": url, \"js_timeout\": \"30\", \"media\": \"true\"}\n",
        "    headers = {\n",
        "        \"X-RapidAPI-Key\": \"8a62fe820amsh2a4a72771032a6cp1b6f99jsn339a1fcd31ca\",\n",
        "        \"X-RapidAPI-Host\": \"lexper.p.rapidapi.com\"\n",
        "    }\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        async with session.get(lexper_url, headers=headers, params=querystring) as response:\n",
        "            data = await response.json()\n",
        "            html = data.get('article', {}).get('html', '')\n",
        "            htmlParse = BeautifulSoup(html, 'html.parser')\n",
        "            text = \"\"\n",
        "            for para in htmlParse.find_all(['p', 'h1', 'h2', 'h3']):\n",
        "                text += para.get_text().lstrip() + \"\\n\"\n",
        "            return index, text\n",
        "\n",
        "async def main(csv_filename):\n",
        "    google_news = GNews()\n",
        "    google_news.max_results = 10\n",
        "    google_news.country = 'United States'\n",
        "    google_news.language = 'english'\n",
        "    google_news.exclude_websites = [\"congress.gov\", 'house.gov', \"senate.gov\"]\n",
        "    news_list = pd.DataFrame(columns=['Name', 'Title', 'Date', 'URL'])\n",
        "    seven_days_ago = datetime.now() - timedelta(days=7)\n",
        "\n",
        "    # Read the CSV file and extract the 'full_name' column as a list of representatives\n",
        "    representatives = pd.read_csv(csv_filename)['full_name'].tolist()\n",
        "\n",
        "    tasks = []\n",
        "    for rep in representatives:\n",
        "        rep_name = \"Rep.\" + rep\n",
        "        # Get news articles for each representative\n",
        "        news = google_news.get_news(rep_name)\n",
        "        for info in news:\n",
        "            # Create a task for processing each news article asynchronously\n",
        "            task = asyncio.create_task(process_news(info, seven_days_ago, rep))\n",
        "            tasks.append(task)\n",
        "\n",
        "    # Gather all the results from the tasks\n",
        "    result = await asyncio.gather(*tasks)\n",
        "\n",
        "    # Concatenate the non-empty DataFrames into a single DataFrame\n",
        "    news_list = pd.concat([df for df in result if df is not None], ignore_index=True)\n",
        "\n",
        "    # Fetch the result text for each URL\n",
        "    tasks = []\n",
        "    result_texts = {}\n",
        "    for i, url in enumerate(news_list['URL']):\n",
        "        task = asyncio.create_task(fetch_result_text(i, url))\n",
        "        tasks.append(task)\n",
        "        await asyncio.sleep(1)  # Add a delay of 1 second between each request\n",
        "\n",
        "    result_texts = await asyncio.gather(*tasks)\n",
        "\n",
        "    # Update the 'ResultText' column in the DataFrame\n",
        "    for index, text in result_texts:\n",
        "        news_list.at[index, 'ResultText'] = text\n",
        "\n",
        "    # Return the final DataFrame with news information\n",
        "    return news_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WUaWPSq4yJi"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "# Run the main function\n",
        "  csv_filename = 'Test2.csv'  # Replace with the actual CSV file name\n",
        "  result = await main(csv_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dAbVc72_0Do"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amIAjcs8I9yl"
      },
      "source": [
        "# Get list without article text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def get_news_articles(keyword, days):\n",
        "    # Encode the keyword to be used in the URL\n",
        "    encoded_keyword = keyword.replace(' ', '+')\n",
        "\n",
        "    # Calculate the start date 'days' ago from the current date\n",
        "    start_date = datetime.now() - timedelta(days=days)\n",
        "\n",
        "    # Format the start date and current date\n",
        "    formatted_start_date = start_date.strftime('%Y-%m-%d')\n",
        "    formatted_current_date = datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "    # Google News URL for the keyword search and date range\n",
        "    url = f\"https://news.google.com/search?q={encoded_keyword}&hl=en-US&gl=US&ceid=US%3Aen&daterange={formatted_start_date}_{formatted_current_date}\"\n",
        "\n",
        "    # Send a GET request to the URL\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Parse the HTML content using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Find all the news articles on the page\n",
        "    articles = soup.find_all('article')\n",
        "\n",
        "    # Calculate the date threshold for comparison\n",
        "    date_threshold = datetime.now() - timedelta(days=days)\n",
        "\n",
        "    news_list = []\n",
        "    for article in articles:\n",
        "        # Extract the title, date published, and URL for each article\n",
        "        title = article.find('h3', class_='ipQwMb ekueJc RD0gLb').text\n",
        "        date_published = article.find('time')['datetime']\n",
        "        article_url = 'https://news.google.com' + article.find('a')['href'][1:]\n",
        "\n",
        "        # Convert the date string to a datetime object\n",
        "        article_date = datetime.strptime(date_published, '%Y-%m-%dT%H:%M:%SZ')\n",
        "\n",
        "        # Check if the article date is greater than or equal to the threshold\n",
        "        if article_date >= date_threshold:\n",
        "            # Append the article details to the news list\n",
        "            news_list.append({\n",
        "                'Title': title,\n",
        "                'Date Published': date_published,\n",
        "                'URL': article_url\n",
        "            })\n",
        "\n",
        "    return news_list\n"
      ],
      "metadata": {
        "id": "IhQgWB2OU5T5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyword = \"Rep. Mike Levin\"\n",
        "days = 10\n",
        "\n",
        "news_articles = get_news_articles(keyword, 3)\n"
      ],
      "metadata": {
        "id": "LVWL5aNaU6SW"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_articles"
      ],
      "metadata": {
        "id": "ponCA79YVdGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "Ts20Tgh_fV_g"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from newscatcherapi import NewsCatcherApiClient\n",
        "\n",
        "newscatcherapi = NewsCatcherApiClient(x_api_key='biQVwhEMQQ1Vgt_2SkUajTemhW8H8LW3gJHuzSALBg8')\n",
        "\n",
        "async def fetch(session, url):\n",
        "    async with session.get(url) as response:\n",
        "        return await response.text()\n",
        "\n",
        "async def process_news(info, date_threshold, rep):\n",
        "    date_format = '%a, %d %b %Y %H:%M:%S %Z'\n",
        "    news_row = None\n",
        "    try:\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            async with session.get(info[\"url\"]) as response:\n",
        "                if response.status == 200:\n",
        "                    content = await response.text()\n",
        "                    if content and not content.startswith(\"https://consent.google.com/\"):\n",
        "                        final_url = extract_final_url(content)\n",
        "                        if final_url:\n",
        "                            published_date = datetime.strptime(info[\"published date\"], date_format)\n",
        "                            if published_date >= date_threshold:\n",
        "                                news_row = {\n",
        "                                    'Name': rep,\n",
        "                                    'Title': info[\"title\"],\n",
        "                                    'Date': info[\"published date\"],\n",
        "                                    'URL': final_url\n",
        "                                }\n",
        "    except aiohttp.ClientError as e:\n",
        "        print(\"URL not working:\", e)\n",
        "\n",
        "    return pd.DataFrame(news_row, index=[0]) if news_row else None\n",
        "\n",
        "def extract_final_url(html_content):\n",
        "    match = re.search(r'<a\\s+href=[\\'\"]?([^\\'\" >]+)', html_content)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    return None\n",
        "\n",
        "async def main(csv_filename, sheet_name, days):\n",
        "    google_news = GNews()\n",
        "    google_news.max_results = 10\n",
        "    google_news.country = 'United States'\n",
        "    google_news.language = 'english'\n",
        "    google_news.exclude_websites = [\"congress.gov\", 'house.gov', \"senate.gov\"]\n",
        "    news_list = pd.DataFrame(columns=['Name', 'Title', 'Date', 'URL'])\n",
        "    date_threshold = datetime.utcnow() - timedelta(days=days)\n",
        "\n",
        "    if sheet_name:\n",
        "        representatives = pd.read_excel(csv_filename, sheet_name)['full_name'].tolist()\n",
        "    else:\n",
        "        representatives = pd.read_csv(csv_filename)['full_name'].tolist()\n",
        "\n",
        "    tasks = []\n",
        "    results = []  # Store the data frames returned by process_news\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        for rep in representatives:\n",
        "            print(rep)\n",
        "            rep_name = \"Rep.\" + rep\n",
        "            news = newscatcherapi.get_search(q='Rep. Mike Levin',\n",
        "                                         lang='en',\n",
        "                                         countries='US',\n",
        "                                         from_= '3 days ago',\n",
        "                                         page_size=20)\n",
        "\n",
        "            print(news)\n",
        "            for info in news:\n",
        "                task = asyncio.create_task(process_news(info, date_threshold, rep))\n",
        "                tasks.append(task)\n",
        "\n",
        "                # Limit the number of simultaneous requests\n",
        "                if len(tasks) >= 10:\n",
        "                    # Await the tasks and store the data frames in the results list\n",
        "                    news_data = await asyncio.gather(*tasks)\n",
        "                    results.extend(news_data)\n",
        "                    tasks = []\n",
        "\n",
        "        if tasks:\n",
        "            news_data = await asyncio.gather(*tasks)\n",
        "            results.extend(news_data)\n",
        "\n",
        "    if results:\n",
        "        news_list = pd.concat(results, ignore_index=True)\n",
        "\n",
        "    return news_list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With API"
      ],
      "metadata": {
        "id": "oSNBV-gCjXAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install newscatcherapi"
      ],
      "metadata": {
        "id": "Rmf6RfObZIVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from newscatcherapi import NewsCatcherApiClient\n",
        "\n",
        "newscatcherapi = NewsCatcherApiClient(x_api_key='biQVwhEMQQ1Vgt_2SkUajTemhW8H8LW3gJHuzSALBg8')\n",
        "\n",
        "all_articles = newscatcherapi.get_search(q='Rep. Mike Levin',\n",
        "                                         lang='en',\n",
        "                                         countries='US',\n",
        "                                         from_= '3 days ago',\n",
        "                                         page_size=20)"
      ],
      "metadata": {
        "id": "33c0b_ZWZLaf"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_articles['articles']"
      ],
      "metadata": {
        "id": "xzkbcOLaZtJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import time\n",
        "import aiohttp\n",
        "from newscatcherapi import NewsCatcherApiClient\n",
        "\n",
        "\n",
        "def process_news_list(name,articles):\n",
        "    news_data = []\n",
        "    date_format = '%Y-%m-%d %H:%M:%S'\n",
        "\n",
        "    for article in articles:\n",
        "        title = article.get('title', \"\")\n",
        "        url = article.get('link', \"\")\n",
        "        date_str = article.get('published_date', \"\")\n",
        "        summary = article.get('summary', \"\")\n",
        "\n",
        "        # Parse and format the date\n",
        "        if date_str:\n",
        "            try:\n",
        "                published_date = datetime.strptime(date_str, date_format)\n",
        "                date = published_date.strftime('%Y-%m-%d %H:%M:%S')\n",
        "            except ValueError:\n",
        "                date = \"\"\n",
        "\n",
        "        news = {\n",
        "            \"Name\": name,\n",
        "            \"Title\": title,\n",
        "            \"URL\": url,\n",
        "            \"Date\": date,\n",
        "            \"Summary\": summary\n",
        "        }\n",
        "        news_data.append(news)\n",
        "\n",
        "    df = pd.DataFrame(news_data)\n",
        "    return df\n",
        "\n",
        "\n",
        "async def main(csv_filename, sheet_name, days):\n",
        "    news_data = []\n",
        "    date_threshold = datetime.utcnow() - timedelta(days=days)\n",
        "\n",
        "    if sheet_name:\n",
        "        representatives = pd.read_excel(csv_filename, sheet_name)['full_name'].tolist()\n",
        "    else:\n",
        "        representatives = pd.read_csv(csv_filename)['full_name'].tolist()\n",
        "\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        for rep in representatives:\n",
        "            rep_name = \"Rep. \" + rep\n",
        "            news = newscatcherapi.get_search(q=rep_name,\n",
        "                                             lang='en',\n",
        "                                             countries='US',\n",
        "                                             from_='5 days ago',\n",
        "                                             sort_by='date',\n",
        "                                             page_size=20)\n",
        "            print(rep_name)\n",
        "            print(news)\n",
        "            if news['status'] == \"ok\":\n",
        "                news_df = process_news_list(rep_name,news['articles'])\n",
        "                news_data.append(news_df)\n",
        "            time.sleep(1)\n",
        "\n",
        "    news_list = pd.concat(news_data, ignore_index=True)\n",
        "    return news_list"
      ],
      "metadata": {
        "id": "lZMWzqBNcmqW"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_news_list(all_articles['articles'])"
      ],
      "metadata": {
        "id": "g6bOrBrVcs9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "# Run the main function\n",
        "  csv_filename = '1.xlsx'  # Replace with the actual CSV file name\n",
        "  sheet_name = 'Region5'\n",
        "  days = 2\n",
        "  result = await main(csv_filename, sheet_name, days)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "h9agFN30eh-1",
        "outputId": "ba5a9d0a-1d12-4a74-f81f-84b064ff8c74"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rep. Greg Casar\n",
            "{'status': 'ok', 'total_hits': 12, 'page': 1, 'total_pages': 1, 'page_size': 12, 'articles': [{'title': '$2M Grant To Fund 58 Success Coaches At San Antonio Schools', 'author': '', 'published_date': '2023-07-05 10:55:00', 'published_date_precision': 'full', 'link': 'https://woai.iheart.com/featured/san-antonios-first-news/content/2023-07-05-2m-grant-to-fund-58-success-coaches-at-san-antonio-schools', 'clean_url': 'iheart.com', 'excerpt': 'More than $2 million federal dollars will fund the placement of volunteers at local schools to help motivate students.', 'summary': \"More than $2 million federal dollars will fund the placement of volunteers at local schools to help motivate students. U.S. Reps. Joaquin Castro and Greg Casar recently announced that they'd secured the AmeriCorps funding for the San Antonio chapter of the nonprofit City Year. The funding will place 58 Student Success Coaches on the campuses of eight local schools to help kids improve their literacy, math, and social skills. The coaches will wear red City Year jackets on campus so students can recognize them.\", 'rights': 'iheart.com', 'rank': 799, 'topic': 'news', 'country': 'US', 'language': 'en', 'authors': '', 'media': 'https://i.iheart.com/v3/re/assets.getty/62bbbe7959148f6de694c5b9?ops=gravity(%22north%22),fit(1200,675),quality(65)', 'is_opinion': False, 'twitter_account': '@1200WOAI', '_score': 32.398384, '_id': '48ce84770ea8aa202cbbc583f50fd392'}, {'title': '$2 million grant places 58 Student Success Coaches in local schools to offer kids extra support', 'author': 'Courtney Friedman', 'published_date': '2023-07-04 23:24:02', 'published_date_precision': 'full', 'link': 'https://www.ksat.com/news/local/2023/07/04/2-million-grant-places-58-student-success-coaches-in-local-schools-to-offer-kids-extra-support/', 'clean_url': 'ksat.com', 'excerpt': 'U.S. Reps. Joaquin Castro and Greg Casar recently announced their offices have secured $2,065,575 in AmeriCorps funding for the nonprofit City Year, a nationwide organization that focuses on bridging', 'summary': \"SAN ANTONIO\\n  U.S. Reps. Joaquin Castro and Greg Casar recently announced their offices have secured $2,065,575 in AmeriCorps funding for the nonprofit\\xa0\\nCity Year\\n, a nationwide organization that focuses on bridging gaps in education.\\nThe\\xa0\\nSan Antonio chapter\\n\\xa0is working with eight local public schools to give their students extra assistance by placing Student Success Coaches on the campuses.\\n'Our Success Coaches are in school before the first bell rings. As they enter the building, (they're) that warm, friendly face there for (students) to see.\", 'rights': 'ksat.com', 'rank': 5211, 'topic': 'news', 'country': 'US', 'language': 'en', 'authors': 'Courtney Friedman,Luis Cienfuegos,Valerie Gomez', 'media': 'https://res.cloudinary.com/graham-media-group/image/upload/f_auto/q_auto/c_thumb,w_700/v1/arc-cf/07-04-2023/t_c3631935fe3c46e4aae8443b49ed7330_name_image.jpg?_a=ATAPphC0', 'is_opinion': False, 'twitter_account': 'KSAT', '_score': 17.764412, '_id': '5cb369d25275a42a65d4594daebf6c57'}, {'title': 'Kremlin open to talks over potential prisoner swap involving detained U.S. journalist Evan Gershkovich', 'author': 'POLITICO', 'published_date': '2023-07-04 12:16:00', 'published_date_precision': 'full', 'link': 'https://headtopics.com/us/kremlin-open-to-talks-over-potential-prisoner-swap-involving-detained-u-s-journalist-evan-gershkovi-40894930', 'clean_url': 'headtopics.com', 'excerpt': 'The U.S. ambassador to Moscow was allowed to visit the Wall Street Journal reporter on Monday for the first time since April.', 'summary': \"The U.S. ambassador to Moscow was allowed to visit the Wall Street Journal reporter on Monday for the first time since April. By 07/04/2023 12:15 PM EDT Link Copied MOSCOW  The Kremlin on Tuesday held the door open for contacts with the U.S.\\nregarding a possible prisoner exchange that could potentially involve jailed Wall Street Journal reporter Evan Gershkovich, but reaffirmed that such talks must be held out of the public eye.\\nAsked whether Monday's consular visits to Gershkovich, who has been held behind bars in Moscow since March on charges of espionage, and Vladimir Dunaev, a Russian citizen in U.\", 'rights': 'headtopics.com', 'rank': 25702, 'topic': 'news', 'country': 'US', 'language': 'en', 'authors': 'POLITICO', 'media': 'https://i.headtopics.com/images/2023/7/4/politico/kremlin-open-to-talks-over-potential-prisoner-swap-kremlin-open-to-talks-over-potential-prisoner-swap-1676263662195974144.webp', 'is_opinion': False, 'twitter_account': 'headtopicscom', '_score': 23.938885, '_id': '5d93babe5737aac2ecc4464eabe4cdbb'}, {'title': \"Olivia Dunne shares 'true tragedy' with her millions of TikTok followers\", 'author': 'Fox News', 'published_date': '2023-07-04 08:55:00', 'published_date_precision': 'full', 'link': 'https://headtopics.com/us/olivia-dunne-shares-true-tragedy-with-her-millions-of-tiktok-followers-40887497', 'clean_url': 'headtopics.com', 'excerpt': \"Olivia Dunne posted a video to her ever-growing TikTok account and revealed what she called a 'true tragedy' -- something most people could probably relate to.\", 'summary': 'Olivia Dunne posted a video to her ever-growing TikTok account and revealed what she called a \\'true tragedy\\' -- something most people could probably relate to. (Jerome Miron-USA TODAY Sports) Indeed, a\"true tragedy.\" Dunne recently spoke about her social media presence and the profitability that comes along with having 7.6 million followers on TikTok and another 4.2 million on Instagram.\\nShe appeared on a recent episode of the\"Full Send Podcast\" and said she had been paid over $500,000 for a single social media post.', 'rights': 'headtopics.com', 'rank': 25702, 'topic': 'news', 'country': 'US', 'language': 'en', 'authors': 'Fox News', 'media': 'https://i.headtopics.com/images/2023/7/4/foxnews/olivia-dunne-shares-true-tragedy-with-her-millions-olivia-dunne-shares-true-tragedy-with-her-millions-1676213032186445825.webp', 'is_opinion': False, 'twitter_account': 'headtopicscom', '_score': 24.46266, '_id': '9e2121b192ef2f4e2b09ecff48937e61'}, {'title': 'Happy Fourth by Teresa Burns Parkhurst', 'author': 'The New Yorker', 'published_date': '2023-07-04 08:50:00', 'published_date_precision': 'full', 'link': 'https://headtopics.com/us/happy-fourth-by-teresa-burns-parkhurst-40887452', 'clean_url': 'headtopics.com', 'excerpt': 'A cartoon by Teresa Burns Parkhurst. NewYorkerCartoons\\\\\\\\', 'summary': 'Happy Fourth by Teresa Burns Parkhurst Date: July 3, 2019 Description: A couple sitting on their porch are addressed by their dog who is holding a liquor bottle and a martini glass. Caption:\"Yeah, happy Fourth.\\nIf you want me, I\\'ll be under your bed, digging myself into an altered state of consciousness.\"\\nUploaded July 3rd, 2019 Statistics Viewed 9,380 Times - Last Visitor from New York, NY on 07/04/2023 at 9:03 AM\\n \\nRead more:\\n \\n \\n \\n{{PageTitle}}\\n \\nStarting Sept. 1, a new law in Texas backed by state Republicans and Gov.', 'rights': 'headtopics.com', 'rank': 25702, 'topic': 'news', 'country': 'US', 'language': 'en', 'authors': 'The New Yorker', 'media': 'https://i.headtopics.com/images/2023/7/4/newyorker/a-cartoon-by-teresa-burns-parkhurst-newyorkercarto-a-cartoon-by-teresa-burns-parkhurst-newyorkercarto-1676211897631219713.webp', 'is_opinion': False, 'twitter_account': 'headtopicscom', '_score': 26.789394, '_id': '9c5fe6ba1022e54a80ce810a35668bc0'}, {'title': 'On July Fourth, this former SEAL wants you to remember what the real price of freedom is', 'author': 'Fox News', 'published_date': '2023-07-04 07:50:00', 'published_date_precision': 'full', 'link': 'https://headtopics.com/us/on-july-fourth-this-former-seal-wants-you-to-remember-what-the-real-price-of-freedom-is-40885731', 'clean_url': 'headtopics.com', 'excerpt': 'OPINION: On July Fourth, this former SEAL wants you to remember what the real price of freedom is', 'summary': 'I served as a SEAL alongside my friend Drago Dzieran. Drago grew up in Communist Poland and never forgot that terrible way of life You can now listen to articles! As he grew older, he rebelled against this draconian way of life and was eventually imprisoned for speaking out against socialist oppression and questioning how he and his fellow Poles people were terrorized...\\nYou can now listen to articles! As he grew older, he rebelled against this draconian way of life and was eventually imprisoned for speaking out against socialist oppression and questioning how he and his fellow Poles people were terrorized and abused.', 'rights': 'headtopics.com', 'rank': 25702, 'topic': 'news', 'country': 'US', 'language': 'en', 'authors': 'Fox News', 'media': 'https://i.headtopics.com/images/2023/7/4/foxnews/on-july-fourth-this-former-seal-wants-you-to-remem-on-july-fourth-this-former-seal-wants-you-to-remem-1676196690066284544.webp', 'is_opinion': False, 'twitter_account': '@headtopicscom', '_score': 24.033047, '_id': '43ab33f62a26ac279cb3ad7bd7a25af6'}, {'title': 'China just played a trump card in the chip war. Are more export curbs coming?', 'author': 'CNN', 'published_date': '2023-07-04 07:00:00', 'published_date_precision': 'full', 'link': 'https://headtopics.com/us/china-just-played-a-trump-card-in-the-chip-war-are-more-export-curbs-coming-cnn-business-40883773', 'clean_url': 'headtopics.com', 'excerpt': 'A trade war between China and the United States over the future of semiconductors is escalating.', 'summary': \"A trade war between China and the United States over the future of semiconductors is escalating.\\nBeijing hit back Monday by playing a trump card: It imposed export controls on two strategic raw materials, gallium and germanium, that are critical to the global chipmaking industry. 'We see this as China's second, and much bigger, counter measure to the tech war, and likely a response to the potential US tightening of [its] AI chip ban,' said Jefferies analysts. Sanctioning one of America's biggest memory chipmakers, Micron Technology\\n \\n (MU), in May was the first, they said.\", 'rights': 'headtopics.com', 'rank': 25702, 'topic': 'news', 'country': 'US', 'language': 'en', 'authors': 'CNN', 'media': 'https://i.headtopics.com/images/2023/7/4/cnn/china-just-played-a-trump-card-in-the-chip-war-are-china-just-played-a-trump-card-in-the-chip-war-are-1676184138301276163.webp', 'is_opinion': False, 'twitter_account': 'headtopicscom', '_score': 16.72291, '_id': '8e01cb2ada4f1d17dfc0dbf85fd0d43d'}, {'title': \"Julian Sands Had Spoken About Dangerous' Mountain Climbing in His Last Interview\", 'author': 'Variety', 'published_date': '2023-07-04 06:37:00', 'published_date_precision': 'full', 'link': 'https://headtopics.com/us/julian-sands-had-spoken-about-dangerous-mountain-climbing-in-his-last-interview-40882874', 'clean_url': 'headtopics.com', 'excerpt': \"Julian Sands, the British actor who was confirmed dead last week after going missing during a mountain hike spoke about 'dangerous' mountain climbing in his last interview. In his last \", 'summary': \"Julian Sands, the British actor who was confirmed dead last week after going missing during a mountain hike spoke about 'dangerous' mountain climbing in his last interview. In his last  after going missing during a mountain hike spoke about 'dangerous' mountain climbing in his last interview. In his last U.K.\\ninterview, with the Radio Times, conducted six months before he was discovered, Sands described climbing as 'solace and a sort of existentialist self-negation, but equally a self-affirmation,' adding 'if you can deal with dangerous mountains, you can certainly deal with life as an actor  the two are quite complementary.\", 'rights': 'headtopics.com', 'rank': 25702, 'topic': 'news', 'country': 'US', 'language': 'en', 'authors': 'Variety', 'media': 'https://i.headtopics.com/images/2023/7/4/variety/julian-sands-had-spoken-about-dangerous-mountain-c-julian-sands-had-spoken-about-dangerous-mountain-c-1676178353353633793.webp', 'is_opinion': False, 'twitter_account': '@headtopicscom', '_score': 24.033047, '_id': 'ca56883f3f1ebef2fe4f7b5657ac2ed6'}, {'title': 'Four migrants, including an infant, drowned in the Rio Grande River over 3-day period, official says', 'author': 'CNN', 'published_date': '2023-07-04 06:00:00', 'published_date_precision': 'full', 'link': 'https://headtopics.com/us/four-migrants-including-an-infant-drowned-in-the-rio-grande-river-over-3-day-period-official-says-40882253', 'clean_url': 'headtopics.com', 'excerpt': 'Law enforcement officers in Texas have recovered the bodies of four drowned migrants, including an infant, from the Rio Grande River along the US-Mexico border since Saturday', 'summary': 'Law enforcement officers in Texas have recovered the bodies of four drowned migrants, including an infant, from the Rio Grande River along the US-Mexico border since Saturday, an official said.\\nThe drownings come just days before Texas officials are expected to begin establishing a floating water barrier along parts of the Rio Grande in an attempt to deter illegal border crossings. The first 1,000 feet of the barrier are set to be deployed near Eagle Pass beginning July 7, Governor Gregg Abbott and other officials announced last month.', 'rights': 'headtopics.com', 'rank': 25702, 'topic': 'news', 'country': 'US', 'language': 'en', 'authors': 'CNN', 'media': 'https://i.headtopics.com/images/2023/7/4/cnn/four-migrants-including-an-infant-drowned-in-the-r-four-migrants-including-an-infant-drowned-in-the-r-1676169057291124738.webp', 'is_opinion': False, 'twitter_account': 'headtopicscom', '_score': 19.865906, '_id': 'a01f2437572eb38649e435de9919bfeb'}, {'title': 'Park Bo Gum In Talks To Make Musical Debut', 'author': 'Soompi', 'published_date': '2023-07-04 05:33:00', 'published_date_precision': 'full', 'link': 'https://headtopics.com/us/park-bo-gum-in-talks-to-make-musical-debut-40881917', 'clean_url': 'headtopics.com', 'excerpt': 'ParkBoGum In Talks To Make Musical Debut', 'summary': \"Park Bo Gum In Talks To Make Musical Debut may be making his highly-anticipated musical debut! On July 4, industry representatives reported that Park Bo Gum will be starring in the upcoming musical 'Let me fly' this coming September and that details are being coordinated.\\nIn response to the report, an official from the investment and distribution company of the musical 'Let me fly' remarked, 'No confirmation has been made regarding the casting for Let me fly.'' Park Bo Gum's agency THEBLACKLABEL shared, 'Park Bo Gum is positively in talks to star in Let me fly.\", 'rights': 'headtopics.com', 'rank': 25702, 'topic': 'news', 'country': 'US', 'language': 'en', 'authors': 'Soompi', 'media': 'https://i.headtopics.com/images/2023/7/4/soompi/parkbogum-in-talks-to-make-musical-debut-parkbogum-in-talks-to-make-musical-debut-1676162196320182272.webp', 'is_opinion': False, 'twitter_account': 'headtopicscom', '_score': 24.627604, '_id': 'e70d0931bb51c6cd9bc7c081db9541e0'}, {'title': 'Vanilla the chimp was born in a lab. At 28, she saw the open sky.', 'author': 'The Washington Post', 'published_date': '2023-07-04 01:01:00', 'published_date_precision': 'full', 'link': 'https://headtopics.com/us/vanilla-the-chimp-was-born-in-a-lab-at-28-she-saw-the-open-sky-40874458', 'clean_url': 'headtopics.com', 'excerpt': 'A video of the chimp staring slack-jawed as she emerged into her new habitat for the first time went viral after it was shared last month by Save the Chimps, a Fort Pierce, Fla., sanctuary.', 'summary': \"A video of Vanilla the chimpanzee taking in the blue sky at a Florida sanctuary went viral. It captured the end of a long journey that began in a lab cage. The clip captured the joyous conclusion to Vanilla's long, turbulent journey through several other homes  none of which allowed her an unobstructed view of the sky, Save the Chimps CEO Ana Paula Tavares told .\\nTo Tavares, the response to Vanilla's milestone was unsurprising. It underscored the similarities between chimpanzees and humans and the urgency of rescuing chimps like Vanilla from mistreatment, she said.\", 'rights': 'headtopics.com', 'rank': 25702, 'topic': 'news', 'country': 'US', 'language': 'en', 'authors': 'The Washington Post', 'media': 'https://i.headtopics.com/images/2023/7/4/washingtonpost/vanilla-the-chimp-was-born-in-a-lab-at-28-she-saw--vanilla-the-chimp-was-born-in-a-lab-at-28-she-saw--1676093801461342209.webp', 'is_opinion': False, 'twitter_account': '@headtopicscom', '_score': 24.250486, '_id': '7b8fccb7cf1e99e1044c39760759eddb'}, {'title': \"San Antonio's VIA gets $3 million in federal grants for low-emission vans\", 'author': 'Brandon Rodriguez', 'published_date': '2023-07-01 09:46:00', 'published_date_precision': 'full', 'link': 'https://www.sacurrent.com/news/san-antonios-via-gets-3-million-in-federal-grants-for-low-emission-vans-32070532', 'clean_url': 'sacurrent.com', 'excerpt': 'The grant will finance the replacement of 15 gasoline-powered vehicles VIA uses to transport people with disabilities.', 'summary': 'By\\n\\n\\n\\nBrandon Rodriguez\\n\\n on\\nSat, Jul 1, 2023 at 9:46 am\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[\\n {\\n \"name\": \"Real 1 Player (r2) - Inline\",\\n \"component\": \"27560945\",\\n \"insertPoint\": \"3\",\\n \"requiredCountToDisplay\": \"5\"\\n },{\\n \"name\": \"Air Ad - NativeInline - Injected\",\\n \"component\": \"27688470\",\\n \"insertPoint\": \"2/3\",\\n \"requiredCountToDisplay\": \"9\"\\n }\\n ]\\n\\n\\n\\n\\n\\n\\n \\n \\n \\n \\n \\n VIA Metropolitan Transit \\n \\n The FTA funding will allow VIAtrans to continue offering crucial transportation services to riders with disabilities in cleaner fuel burning vehicles \\n \\n \\n\\n\\n\\nVIA Metropolitan Transit has received more than $3 million from the Federal Transit Administration through the agency\\'s\\xa0Low or No Emission Vehicle Program, according officials with the transit authority.', 'rights': 'Copyright 2023 San Antonio Current. All rights reserved. This RSS file is offered to individuals, San Antonio Current readers, and non-commercial organizations only. Any commercial websites wishing to use this RSS file, please contact San Antonio Current.', 'rank': 9625, 'topic': 'news', 'country': 'US', 'language': 'en', 'authors': 'Brandon Rodriguez', 'media': 'https://media1.sacurrent.com/sacurrent/imager/u/blog/32070535/holiday_special_bus_at_the_pearl02.jpg', 'is_opinion': False, 'twitter_account': '@SAcurrent', '_score': 23.762688, '_id': '8f576e9b1ccf34b6d6f5ca228f56390a'}], 'user_input': {'q': 'Rep. Greg Casar', 'search_in': ['title_summary_en'], 'lang': ['en'], 'not_lang': None, 'countries': ['US'], 'not_countries': None, 'from': '2023-06-30 19:34:13', 'to': None, 'ranked_only': 'True', 'from_rank': None, 'to_rank': None, 'sort_by': 'date', 'page': 1, 'size': 20, 'sources': None, 'not_sources': [], 'topic': None, 'published_date_precision': None}}\n",
            "Rep. Brian Babin\n",
            "{'status': 'No matches for your search.', 'total_hits': 0, 'page': 0, 'total_pages': 0, 'page_size': 0, 'user_input': {'q': 'Rep. Brian Babin', 'search_in': ['title_summary_en'], 'lang': ['en'], 'not_lang': None, 'countries': ['US'], 'not_countries': None, 'from': '2023-06-30 19:34:15', 'to': None, 'ranked_only': 'True', 'from_rank': None, 'to_rank': None, 'sort_by': 'date', 'page': 1, 'size': 20, 'sources': None, 'not_sources': [], 'topic': None, 'published_date_precision': None}}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NewsCatcherApiException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNewsCatcherApiException\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-214-b9bb1dea2370>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0msheet_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Region5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mdays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-213-93b1eac397ea>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(csv_filename, sheet_name, days)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrepresentatives\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mrep_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Rep. \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             news = newscatcherapi.get_search(q=rep_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                              \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                              \u001b[0mcountries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'US'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/newscatcherapi/newscatcherapi_client.py\u001b[0m in \u001b[0;36mget_search\u001b[0;34m(self, q, lang, not_lang, from_, to_, published_date_precision, search_in, countries, not_countries, topic, sources, not_sources, ranked_only, from_rank, to_rank, sort_by, page_size, page, proxies)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;31m# Check Status of Request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNewsCatcherApiException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNewsCatcherApiException\u001b[0m: {'status': 'error', 'error_code': 'LimitReached', 'message': 'Monthly API calls limit reached: 50'}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "GN9GGs_lfp0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQzR_d9hI0MG"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "# Run the main function\n",
        "  csv_filename = '1.xlsx'  # Replace with the actual CSV file name\n",
        "  sheet_name = 'Region5'\n",
        "  days = 2\n",
        "  result = await main(csv_filename, sheet_name, days)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWZIg0YHI22Y"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "O7FJxzeOxlbn"
      },
      "outputs": [],
      "source": [
        "import firebase_admin\n",
        "from firebase_admin import credentials\n",
        "from firebase_admin import firestore\n",
        "\n",
        "# Replace the path with the location of your service account key file\n",
        "cred = credentials.Certificate('/content/key.json')\n",
        "\n",
        "# Initialize the Firebase Admin SDK\n",
        "firebase_admin.initialize_app(cred)\n",
        "\n",
        "# Create a Firestore client\n",
        "db = firestore.client()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_dataframe_to_firestore(dataframe, collection_name):\n",
        "    # Convert the DataFrame to a list of dictionaries\n",
        "    data = dataframe.to_dict(orient='records')\n",
        "\n",
        "    # Upload each document in the list to Firestore\n",
        "    for document in data:\n",
        "        # Retrieve the URL and Name values from the document\n",
        "        url = document.get('URL')\n",
        "        name = document.get('Name')\n",
        "\n",
        "        # Query Firestore to check if a document with the same URL and Name already exists\n",
        "        query = db.collection(collection_name).where('URL', '==', url).where('Name', '==', name)\n",
        "        existing_docs = query.get()\n",
        "\n",
        "        if len(existing_docs) > 0:\n",
        "            print(f\"Skipping duplicate document with URL: {url} and Name: {name}\")\n",
        "            continue\n",
        "\n",
        "        # Generate a new document ID\n",
        "        doc_ref = db.collection(collection_name).document()\n",
        "\n",
        "        # Set the document data\n",
        "        doc_ref.set(document)\n",
        "\n",
        "    print(\"DataFrame uploaded to Firestore successfully.\")\n",
        "\n",
        "# Example usage\n",
        "collection_name = \"news_collection\"\n",
        "upload_dataframe_to_firestore(result, collection_name)"
      ],
      "metadata": {
        "id": "qcos6lxt_Xrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "dcDrvmfayKVk"
      },
      "outputs": [],
      "source": [
        "def retrieve_data_by_field(collection_name, field_name, search_value):\n",
        "    # Create a reference to the Firestore collection\n",
        "    collection_ref = db.collection(collection_name)\n",
        "\n",
        "    # Get all documents from the collection\n",
        "    all_documents = collection_ref.get()\n",
        "\n",
        "    # Process the documents and filter based on the search field and value\n",
        "    for doc in all_documents:\n",
        "        # Access the document data\n",
        "        data = doc.to_dict()\n",
        "\n",
        "        # Check if the search field and value match the document\n",
        "        if field_name in data and data[field_name] == search_value:\n",
        "            # Do something with the matching data\n",
        "            print(data[\"Title\"])\n",
        "\n",
        "\n",
        "def retrieve_data_by_date(collection_name, search_date):\n",
        "    # Create a reference to the Firestore collection\n",
        "    collection_ref = db.collection(collection_name)\n",
        "\n",
        "    # Get all documents from the collection\n",
        "    all_documents = collection_ref.get()\n",
        "\n",
        "    # Process the documents and filter based on the search date\n",
        "    for doc in all_documents:\n",
        "        # Access the document data\n",
        "        data = doc.to_dict()\n",
        "\n",
        "        # Get the \"Date\" field value and convert it to a datetime object\n",
        "        date_str = data[\"Date\"]\n",
        "        date = datetime.strptime(date_str, \"%a, %d %b %Y %H:%M:%S %Z\").date()\n",
        "\n",
        "        # Check if the date matches the search date\n",
        "        if date.strftime(\"%B %d\") == search_date:\n",
        "            # Do something with the matching data\n",
        "            print(data[\"Title\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "collection_name = \"news_collection\"\n",
        "search_date = datetime.datetime(2023, 7, 4).date().strftime(\"%B %d\")\n",
        "retrieve_data_by_date(collection_name, search_date)\n"
      ],
      "metadata": {
        "id": "XsUvIqp2B7yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "collection_name = \"news_collection\"\n",
        "field_name = \"Name\"\n",
        "search_value = \"Mike Levin\"\n",
        "retrieve_data_by_field(collection_name, field_name, search_value)"
      ],
      "metadata": {
        "id": "6uP_bWAXApHY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b13326e-a1f4-4ee2-d89e-b860f1d76df6"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Playbook: The political fireworks to watch today - POLITICO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By9jeGAHfphP"
      },
      "source": [
        "# Old Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ct1tINNoNfeV"
      },
      "outputs": [],
      "source": [
        "date_format = '%a, %d %b %Y %H:%M:%S %Z'\n",
        "seven_days_ago = datetime.now() - timedelta(days=2)\n",
        "df_final = pd.DataFrame(columns=['title', 'rep', 'link',\"publisher\"])\n",
        "for ind in df.index:\n",
        "    rep = (\"Rep.\" + df['full_name'][ind])\n",
        "    print(rep)\n",
        "    news=google_news.get_news(rep)\n",
        "    for info in news:\n",
        "      try:\n",
        "        url = requests.get(info[\"url\"],timeout=5).url\n",
        "        if datetime.strptime(info[\"published date\"], date_format) >= seven_days_ago:\n",
        "          if not \".gov\" in url:\n",
        "          #df_final.append([info[\"title\"]],[rep],[url],[info[\"publisher\"]])\n",
        "            print(info[\"title\"] + info[\"published date\"])\n",
        "            print(url)\n",
        "        ##print(info[\"title\"] + info[\"published date\"] + \" \" + info[\"url\"])\n",
        "            new_row = pd.DataFrame({\n",
        "                'Name': [df['full_name']],\n",
        "                'Title': [info[\"title\"]],\n",
        "                'URL': [url]\n",
        "            })\n",
        "\n",
        "            # Concatenate the new row with the existing DataFrame\n",
        "            news_list = pd.concat([news_list, new_row], ignore_index=True)\n",
        "      except:\n",
        "        print(\"url not working, try: \")\n",
        "        print(info[\"url\"])\n",
        "    print(\"-\"*100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJjV59YiKraF"
      },
      "outputs": [],
      "source": [
        "date_format = '%a, %d %b %Y %H:%M:%S %Z'\n",
        "seven_days_ago = datetime.now() - timedelta(days=7)\n",
        "rep = (\"Rep.Jerry L. Carl\")\n",
        "print(rep)\n",
        "news=google_news.get_news(rep)\n",
        "for info in news:\n",
        "      try:\n",
        "        response = requests.get(info[\"url\"], allow_redirects=True)\n",
        "        url = response.headers.get(\"Location\") if \"Location\" in response.headers else response.url\n",
        "        if datetime.strptime(info[\"published date\"], date_format) >= seven_days_ago:\n",
        "            if url and not url.startswith(\"https://consent.google.com/\"):\n",
        "                print(info[\"title\"] + info[\"published date\"])\n",
        "                print(url)\n",
        "                new_row = pd.DataFrame({\n",
        "                    'Name': [rep],\n",
        "                    'Title': [info[\"title\"]],\n",
        "                    'Date': [info[\"published date\"]],\n",
        "                    'URL': [url]\n",
        "                })\n",
        "\n",
        "                # Concatenate the new row with the existing DataFrame\n",
        "                news_list = pd.concat([news_list, new_row], ignore_index=True)\n",
        "      except:\n",
        "        print(\"url not working\")\n",
        "print(\"-\"*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Du1i7G59EzZ"
      },
      "source": [
        "## Get Article Text from URL Not as a full function\n",
        "This is used when the publisher requires you to get subscription"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dw5H6hJxjDMs"
      },
      "outputs": [],
      "source": [
        "for site in urllist:\n",
        "    url = \"https://lexper.p.rapidapi.com/v1.1/extract\"\n",
        "    querystring = {\"url\":site,\"js_timeout\":\"30\",\"media\":\"true\"}\n",
        "    headers = {\n",
        "\t    \"X-RapidAPI-Key\": \"8a62fe820amsh2a4a72771032a6cp1b6f99jsn339a1fcd31ca\",\n",
        "  \t  \"X-RapidAPI-Host\": \"lexper.p.rapidapi.com\"\n",
        "    }\n",
        "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
        "\n",
        "    print(site)\n",
        "    html = (response.json()['article']['html'])\n",
        "    htmlParse = bs(html, 'html.parser')\n",
        "    str=\"\"\n",
        "    for para in htmlParse.find_all(['p','h1','h2','h3']):\n",
        "      str = str + para.get_text().lstrip() + \"\\n\"\n",
        "    print(str)\n",
        "    print(\"-\"*100)\n",
        "\n",
        "\n",
        "    sleep(1.5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NgmM_wQzOMXA",
        "l_33eYnvJ2O3",
        "OD0_4hbzNMVn",
        "2owA-f5qWTTE",
        "By9jeGAHfphP"
      ],
      "authorship_tag": "ABX9TyOUtH0X/ExSNL+34zXAkEFY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}